# Deep-Q-Networks-for-Pac-Man
EC418 Final Project: DQN for Pac-Man using actor-critic method along with a ResNet

# Default: 
[spiral_harder] Episode  200 | reward =  -42.1
Episode 1: LOSE in 31 steps
Episode 2: LOSE in 21 steps
Episode 3: LOSE in 87 steps
Episode 4: WIN in 50 steps
Episode 5: LOSE in 31 steps
Episode 6: LOSE in 23 steps
Episode 7: LOSE in 13 steps
Episode 8: WIN in 28 steps
Episode 9: LOSE in 59 steps
Episode 10: LOSE in 51 steps

2/10 wins (20.0%)

# ResNet: 
- Allows us to have a deeper model that trains more efficiently; Essentially having less parameters. This architecture skip happens when number of channels or resolution changes. This promotes better feature reuse, allows learning of "deeper" sentimental features in gameplay thus improving decision making.

FINAL RESULTS:
Wins: 1/10 (10.0%) #simplified resnet

